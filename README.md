# Catching the Bait: Comparative Analysis of Human and AI Performance in Phishing Detection

## Introduction

This project investigates the capability of both humans and large language models (LLMs) to discern the origin of personalized phishing messages, highlighting the defensive use of natural language processing (NLP) techniques against cyber threats. The rapid advancement and adoption of LLMs have enabled the generation of highly convincing, human-like text, which can be leveraged in crafting personalized phishing attacks. This project addresses a critical gap in cybersecurity by evaluating how well humans and AI can identify the source of phishing messages—whether they are crafted by humans or generated by LLMs.

Our study involves a dataset of phishing messages, half generated by state-of-the-art LLMs (e.g., GPT-4, Claude-Haiku, Mistral, LLaMA-70B) and the other half by human participants. The messages were personalized based on fabricated profiles detailing various demographic and personal attributes. The project’s evaluation consists of two main tasks: 

1. **Detection**: Participants identify whether a message was authored by a human or an AI.
2. **Selection**: Participants choose between two phishing messages crafted for the same fictitious profile, identifying which one was written by a human.

The findings reveal significant challenges in distinguishing between human and AI-generated phishing messages, even for advanced LLMs, and underscore the need for adaptive security measures to counter increasingly sophisticated cyber threats.


## Files Description:
1. select_fabricated_users_data.py:
Samples from the fabricated users dataset a 100 people for tailoring phishing messages to and another 4 to produce fewshot examples for.

2. create_phishing_mistral.ipynb & create_phishing_gpt_claude.py & create_phishing_llama:
These python script and notebook query Mistral, GPT, Claude and Llama3-8b models to produce customized phishing messages tailored to the provided fabricated users dataset provided.
The llama code runs on HUJI cluster while the other Python code runs locally. All code uses the utility clients provided by the corresponding companies.

3. question_mistral & phishing_turing_detection.yaml & phishing_turing_selection.yaml:
We utilized [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness), an evaluation framework providing out-of-the-box LLM response processing and organizing.
The two .yaml configuration files control the inference settings for the framework inference runs and we utilized their CLI tool to query the GPT, Claude and Llama models. We could not use the library for the Mistral models so we created another Python script to do exactly that.
The Mistral questioning file contains code that queries Mistral in a consistent way with the other models-questioning.

4. create_questionnaires.py:
This Python script samples questions of both types and prepares a .docx questionnaire ready to be printed for human subjects questioning.

5. util.py:
A Python file utilized in the models evaluation, referenced in the .yaml file.

## To reproduce our results:

1. Use select_fabricated_users_data.py to create datasets of random fabricated users and another small fabricated random users for fewshot prompts.
2. Use the create_phishing_* scripts to query the LLMs (note, you will have to fill in API keys) for phishing messages. This is a semi-automatic process as it requires merging the results in a single CSV later which will hold the human phishing messages as well.
3. Gather human-produced phishing messages for every entry in the fabricated users dataset. We've done this with [Prolific](https://jatos.mindprobe.eu/publix/cFBNkXQWCVA).
4. This is optional, but you can conviniently place the datasets (one main dataset and another smaller one for the fewshot prompts) in Huggingface.
5. Run question_mistral.py to query Mistral and generate its responses for the two types of questions for the entire dataset.
6. Use the .yaml files and run the following command: 

        lm_eval --model hf --model_args "pretrained=model" --tasks=turing_phishing_detection_fewshot,turing_phishing_selection_fewshot,turing_phishing_detection_zeroshot,turing_phishing_selection_zeroshot  --verbosity DEBUG --batch_size auto --output_path "path" --log_samples --show_config --cache_requests=refresh

Run this command for every model.

7. Use analyize_results.ipynb to produce the models evaluation accuracies for the fewshot, zeroshot and both selection and detection accuracies.
